{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Representation \n",
    "\n",
    "The classifiers and learning algorithms can not directly process the text documents in their original form,as most of them expect numerical feature vectors with a fixed size rather than raw text docs with variable length. Therefore , during the preprocessing step, the texts are converted to a more manageable representation.\n",
    "\n",
    "One common approach for extracting features from text is to use the bag of words model: a model where for each document, a resume in our case, the presence (and often the frequency) of words is taken into consideration, but the order in which they occur is ignored. \n",
    "\n",
    "TermFrequency and InverseDocumentFrequency is used for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'John H. Smith, P.H.R.\\n800-991-5187 | PO Box...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'Name Surname\\nAddress\\nMobile No/Email\\nPERS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'Anthony Brown\\nHR Assistant\\nAREAS OF EXPERT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>HR</td>\n",
       "      <td>b'www.downloadmela.com\\nSatheesh\\nEMAIL ID:\\nC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>HR</td>\n",
       "      <td>b\"HUMAN RESOURCES DIRECTOR\\n\\xef\\x82\\xb7Expert...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Category                                             Resume\n",
       "0   1       HR  b'John H. Smith, P.H.R.\\n800-991-5187 | PO Box...\n",
       "1   2       HR  b'Name Surname\\nAddress\\nMobile No/Email\\nPERS...\n",
       "2   3       HR  b'Anthony Brown\\nHR Assistant\\nAREAS OF EXPERT...\n",
       "3   4       HR  b'www.downloadmela.com\\nSatheesh\\nEMAIL ID:\\nC...\n",
       "4   5       HR  b\"HUMAN RESOURCES DIRECTOR\\n\\xef\\x82\\xb7Expert..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../Data/resume_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data and adding in ID for category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "col = ['Category', 'Resume']\n",
    "df = df[col]\n",
    "df = df[pd.notnull(df['Resume'])]\n",
    "df.columns = ['Category', 'Resume']\n",
    "df['category_id'] = df['Category'].factorize()[0]\n",
    "category_id_df = df[['Category', 'category_id']].drop_duplicates().sort_values('category_id')\n",
    "category_to_id = dict(category_id_df.values)\n",
    "id_to_category = dict(category_id_df[['category_id', 'Category']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1219, 27968)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1,2), stop_words='english')\n",
    "features = tfidf.fit_transform(df.Resume).toarray()\n",
    "labels = df.category_id\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using chi2 to see correlated items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'Accountant':\n",
      "  . Most correlated unigrams:\n",
      "\t. chartered\n",
      "\t. accountant\n",
      "  . Most correlated bigrams:\n",
      "\t. x82 xa0\n",
      "\t. accountant resume\n",
      "\n",
      "\n",
      "\n",
      "# 'Advocate':\n",
      "  . Most correlated unigrams:\n",
      "\t. legal\n",
      "\t. law\n",
      "  . Most correlated bigrams:\n",
      "\t. law school\n",
      "\t. school law\n",
      "\n",
      "\n",
      "\n",
      "# 'Agricultural':\n",
      "  . Most correlated unigrams:\n",
      "\t. plants\n",
      "\t. horticulture\n",
      "  . Most correlated bigrams:\n",
      "\t. npart american\n",
      "\t. 5890 nj\n",
      "\n",
      "\n",
      "\n",
      "# 'Apparel':\n",
      "  . Most correlated unigrams:\n",
      "\t. nfashion\n",
      "\t. fashion\n",
      "  . Most correlated bigrams:\n",
      "\t. interior design\n",
      "\t. space planning\n",
      "\n",
      "\n",
      "\n",
      "# 'Architects':\n",
      "  . Most correlated unigrams:\n",
      "\t. tower\n",
      "\t. drawings\n",
      "  . Most correlated bigrams:\n",
      "\t. cad xef\n",
      "\t. auto cad\n",
      "\n",
      "\n",
      "\n",
      "# 'Arts':\n",
      "  . Most correlated unigrams:\n",
      "\t. artist\n",
      "\t. theatre\n",
      "  . Most correlated bigrams:\n",
      "\t. art institute\n",
      "\t. nheight xe2\n",
      "\n",
      "\n",
      "\n",
      "# 'Automobile':\n",
      "  . Most correlated unigrams:\n",
      "\t. automobile\n",
      "\t. automotive\n",
      "  . Most correlated bigrams:\n",
      "\t. nphone 586\n",
      "\t. michigan nphone\n",
      "\n",
      "\n",
      "\n",
      "# 'Aviation':\n",
      "  . Most correlated unigrams:\n",
      "\t. attendant\n",
      "\t. flight\n",
      "  . Most correlated bigrams:\n",
      "\t. nflight attendant\n",
      "\t. flight attendant\n",
      "\n",
      "\n",
      "\n",
      "# 'BPO':\n",
      "  . Most correlated unigrams:\n",
      "\t. ncall\n",
      "\t. bpo\n",
      "  . Most correlated bigrams:\n",
      "\t. ymail com\n",
      "\t. ncall center\n",
      "\n",
      "\n",
      "\n",
      "# 'Banking':\n",
      "  . Most correlated unigrams:\n",
      "\t. bank\n",
      "\t. banking\n",
      "  . Most correlated bigrams:\n",
      "\t. na nl\n",
      "\t. nl ne\n",
      "\n",
      "\n",
      "\n",
      "# 'Building & Construction':\n",
      "  . Most correlated unigrams:\n",
      "\t. construction\n",
      "\t. nconstruction\n",
      "  . Most correlated bigrams:\n",
      "\t. space entry\n",
      "\t. site safety\n",
      "\n",
      "\n",
      "\n",
      "# 'Business Development':\n",
      "  . Most correlated unigrams:\n",
      "\t. temple\n",
      "\t. jad\n",
      "  . Most correlated bigrams:\n",
      "\t. administration graduation\n",
      "\t. business analyst\n",
      "\n",
      "\n",
      "\n",
      "# 'Consultant':\n",
      "  . Most correlated unigrams:\n",
      "\t. consultant\n",
      "\t. seoul\n",
      "  . Most correlated bigrams:\n",
      "\t. consultant xef\n",
      "\t. management consultant\n",
      "\n",
      "\n",
      "\n",
      "# 'Designing':\n",
      "  . Most correlated unigrams:\n",
      "\t. graphic\n",
      "\t. designer\n",
      "  . Most correlated bigrams:\n",
      "\t. ngraphic designer\n",
      "\t. graphic design\n",
      "\n",
      "\n",
      "\n",
      "# 'Digital Media':\n",
      "  . Most correlated unigrams:\n",
      "\t. nsocial\n",
      "\t. media\n",
      "  . Most correlated bigrams:\n",
      "\t. mass communication\n",
      "\t. social media\n",
      "\n",
      "\n",
      "\n",
      "# 'Education':\n",
      "  . Most correlated unigrams:\n",
      "\t. elementary\n",
      "\t. teacher\n",
      "  . Most correlated bigrams:\n",
      "\t. elementary school\n",
      "\t. special education\n",
      "\n",
      "\n",
      "\n",
      "# 'Engineering':\n",
      "  . Most correlated unigrams:\n",
      "\t. matlab\n",
      "\t. engineering\n",
      "  . Most correlated bigrams:\n",
      "\t. chemical engineering\n",
      "\t. mechanical engineering\n",
      "\n",
      "\n",
      "\n",
      "# 'Finance':\n",
      "  . Most correlated unigrams:\n",
      "\t. financial\n",
      "\t. finance\n",
      "  . Most correlated bigrams:\n",
      "\t. financial analyst\n",
      "\t. finance manager\n",
      "\n",
      "\n",
      "\n",
      "# 'Food & Beverages':\n",
      "  . Most correlated unigrams:\n",
      "\t. culinary\n",
      "\t. chef\n",
      "  . Most correlated bigrams:\n",
      "\t. culinary arts\n",
      "\t. food service\n",
      "\n",
      "\n",
      "\n",
      "# 'HR':\n",
      "  . Most correlated unigrams:\n",
      "\t. nhr\n",
      "\t. hr\n",
      "  . Most correlated bigrams:\n",
      "\t. human resources\n",
      "\t. downloadmela com\n",
      "\n",
      "\n",
      "\n",
      "# 'Health & Fitness':\n",
      "  . Most correlated unigrams:\n",
      "\t. patient\n",
      "\t. patients\n",
      "  . Most correlated bigrams:\n",
      "\t. health care\n",
      "\t. patient care\n",
      "\n",
      "\n",
      "\n",
      "# 'Information Technology':\n",
      "  . Most correlated unigrams:\n",
      "\t. java\n",
      "\t. developer\n",
      "  . Most correlated bigrams:\n",
      "\t. software engineer\n",
      "\t. computer science\n",
      "\n",
      "\n",
      "\n",
      "# 'Managment':\n",
      "  . Most correlated unigrams:\n",
      "\t. manager\n",
      "\t. pmp\n",
      "  . Most correlated bigrams:\n",
      "\t. office manager\n",
      "\t. x83 xc2\n",
      "\n",
      "\n",
      "\n",
      "# 'Public Relations':\n",
      "  . Most correlated unigrams:\n",
      "\t. boone\n",
      "\t. insert\n",
      "  . Most correlated bigrams:\n",
      "\t. college radio\n",
      "\t. service resume\n",
      "\n",
      "\n",
      "\n",
      "# 'Sales':\n",
      "  . Most correlated unigrams:\n",
      "\t. gadgets\n",
      "\t. sales\n",
      "  . Most correlated bigrams:\n",
      "\t. generating analyzing\n",
      "\t. analyzing monthly\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "N = 2\n",
    "for Category, category_id in sorted(category_to_id.items()):\n",
    "    features_chi2 = chi2(features, labels == category_id)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    #trigrams = [v for v in feature_names if len(v.split(' ')) == 3] \n",
    "    print(\"# '{}':\".format(Category))\n",
    "    print(\"  . Most correlated unigrams:\\n\\t. {}\".format('\\n\\t. '.join(unigrams[-N:])))\n",
    "    print(\"  . Most correlated bigrams:\\n\\t. {}\".format('\\n\\t. '.join(bigrams[-N:])))\n",
    "    print(\"\\n\\n\")\n",
    "    #print(\"  . Most correlated trigrams:\\n. {}\".format('\\n. '.join(trigrams[-N:])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
